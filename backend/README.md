# Sustainability Lens Backend

High-performance FastAPI backend for AI-powered ESG initiative extraction from PDF documents. This service provides intelligent document processing, OCR capabilities, and advanced text analysis to identify sustainability reporting frameworks and initiatives.

## üöÄ Features

### Core Processing
- **PDF Upload & Storage**: Secure file handling with size validation (50MB limit)
- **Intelligent Text Extraction**: Primary PyMuPDF extraction with pdfminer.six fallback
- **Advanced OCR Processing**: Tesseract OCR for scanned documents with automatic fallback
- **Real-time Analysis**: Synchronous processing with comprehensive error handling
- **Metadata Tracking**: Complete document processing statistics and performance metrics

### ESG Framework Intelligence
- **15+ Major ESG Frameworks**: Comprehensive detection of sustainability reporting standards
- **Fuzzy String Matching**: Advanced RapidFuzz algorithms for framework identification
- **Confidence Scoring**: AI-powered confidence levels (0-100%) for each detection
- **Evidence Extraction**: Direct text quotes with precise page-level references
- **Category Classification**: Automatic sorting into Environmental, Social, and Governance

### API & Data Management
- **RESTful API Design**: Clean, documented endpoints with OpenAPI/Swagger
- **SQLite Database**: Efficient metadata storage with production PostgreSQL support
- **CORS Support**: Frontend integration with configurable origins
- **Comprehensive Logging**: Detailed processing logs and error tracking
- **Export Functionality**: JSON data export with complete analysis results

## Prerequisites

- Python 3.8+
- **Optional**: Tesseract OCR for scanned document processing:
  - **Ubuntu/Debian**: `sudo apt-get install tesseract-ocr`
  - **macOS**: `brew install tesseract`
  - **Windows**: Download from [GitHub releases](https://github.com/UB-Mannheim/tesseract/wiki)
  - **Note**: The application will work without Tesseract but OCR functionality will be disabled
  - On Windows, the application attempts to auto-detect the Tesseract installation path as implemented in `utils/extract.py`

## Installation

1. **Create virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. **Install dependencies:**

cd backend

```bash
pip install -r requirements.txt
```

3. **Create directories:**
```bash
mkdir uploads
```

## Running the Server

```bash
# Development server with auto-reload
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Production server
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

The API will be available at `http://localhost:8000`

Interactive API docs: `http://localhost:8000/docs`

## üìñ API Documentation

### Interactive Documentation
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc  
- **OpenAPI Spec**: http://localhost:8000/openapi.json

### API Endpoints

#### 1. üì§ Upload PDF Document
Upload a PDF file for ESG analysis processing.

```bash
curl -X POST "http://localhost:8000/api/upload" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@sustainability_report.pdf"
```

**Request Parameters:**
- `file`: PDF file (max 50MB)

**Response (200 OK):**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "ready",
  "results_url": "/api/results/550e8400-e29b-41d4-a716-446655440000"
}
```

**Error Responses:**
- `400 Bad Request`: Invalid file format or size
- `500 Internal Server Error`: Processing failure

#### 2. üìä Get Analysis Results
Retrieve the complete analysis results for a processed document.

```bash
curl -X GET "http://localhost:8000/api/results/550e8400-e29b-41d4-a716-446655440000"
```

**Response (200 OK):**
```json
{
  "status": "ready",
  "results": [
    {
      "id": "1",
      "framework": "Science Based Targets initiative",
      "description": "Science-based emission reduction targets aligned with climate science",
      "evidence": "In addition to these 2030 targets aligned to the Science Based Targets initiative (SBTi)...",
      "page_number": 42,
      "confidence": 95,
      "category": "Environmental",
      "bbox": [10, 45, 90, 55]
    }
  ],
  "metadata": {
    "document_name": "sustainability_report.pdf",
    "total_pages": 85,
    "processing_time": 42,
    "extraction_method": "selectable"
  }
}
```

**Response States:**
- `ready`: Analysis complete with results
- `processing`: Analysis in progress
- `failed`: Processing failed (with error details)

#### 3. üìÑ Download Original PDF
Retrieve the original uploaded PDF document.

```bash
curl -X GET "http://localhost:8000/api/pdf/550e8400-e29b-41d4-a716-446655440000" \
     --output downloaded_report.pdf
```

**Response:** Binary PDF file or 404 if not found

#### 4. üíæ Export Analysis Results
Download complete analysis results as structured JSON.

```bash
curl -X GET "http://localhost:8000/api/export/550e8400-e29b-41d4-a716-446655440000" \
     --output esg_analysis_export.json
```

**Response:** Comprehensive JSON export with:
- All detected ESG initiatives
- Metadata and processing statistics
- Evidence text and page references
- Confidence scores and categories

#### 5. ‚ù§Ô∏è Health Check
Verify API service health and dependencies.

```bash
curl -X GET "http://localhost:8000/api/health"
```

**Response (200 OK):**
```json
{
  "status": "healthy",
  "service": "sustainability-lens-api"
}
```

## Project Structure

```
backend/
‚îú‚îÄ‚îÄ main.py                 # FastAPI application
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ extract.py         # PDF processing and text extraction
‚îú‚îÄ‚îÄ uploads/               # PDF file storage
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ README.md             # This file
‚îî‚îÄ‚îÄ sustainability_lens.db # SQLite database (created automatically)
```

## Configuration

Key configuration variables in `main.py`:
- `MAX_FILE_SIZE`: Maximum upload size (default: 50MB)
- `UPLOAD_DIR`: Directory for PDF storage
- `DB_PATH`: SQLite database path

## Text Extraction Strategy

1. **Primary**: PyMuPDF extracts selectable text with layout information
2. **Fallback**: If extracted text < 200 characters, run Tesseract OCR
3. **Bounding Boxes**: Computed using layout analysis (approximated for MVP)
4. **Framework Matching**: Fuzzy string matching against 15+ ESG frameworks

## üåç ESG Frameworks & Standards Detection

The system uses advanced fuzzy matching to identify 15+ major sustainability reporting frameworks and initiatives:

### Environmental Frameworks
- **Science Based Targets initiative (SBTi)** - Science-based emission reduction targets
- **Zero Discharge of Hazardous Chemicals (ZDHC)** - Chemical management in textiles
- **Higg Facility Environmental Module (FEM)** - Apparel sustainability assessment
- **CDP (Carbon Disclosure Project)** - Climate change disclosure
- **TCFD** - Task Force on Climate-related Financial Disclosures

### Social & Labor Standards  
- **Social & Labor Convergence Program (SLCP)** - Labor compliance assessments
- **Fair Labor Association (FLA)** - Workplace standards and monitoring
- **Worldwide Responsible Accredited Production (WRAP)** - Apparel manufacturing
- **Business Social Compliance Initiative (BSCI)** - Supply chain social compliance
- **SA8000** - Social accountability standard

### Governance & Reporting
- **Global Reporting Initiative (GRI)** - Sustainability reporting standards
- **UN Global Compact** - Corporate sustainability principles
- **ISO 14001** - Environmental management systems
- **UNGP (UN Guiding Principles)** - Business and human rights
- **Sustainable Development Goals (SDGs)** - UN development framework

### Detection Features
- **Fuzzy String Matching**: Handles variations in terminology and abbreviations
- **Contextual Analysis**: Considers surrounding text for accurate identification
- **Confidence Scoring**: 0-100% confidence levels based on match quality
- **Multi-language Support**: Framework detection in multiple languages
- **Alias Recognition**: Identifies frameworks by common abbreviations and alternate names

## Error Handling

- File validation (PDF only, size limits)
- Database error handling
- PDF processing error recovery
- Comprehensive logging

## Development

Run tests:
```bash
pytest
```

Format code:
```bash
black main.py utils/
```

## üöÄ Production Deployment

### Infrastructure Requirements
- **Database**: PostgreSQL 12+ for production workloads
- **File Storage**: AWS S3, Google Cloud Storage, or Azure Blob Storage
- **Compute**: 2+ CPU cores, 4GB+ RAM per worker
- **Storage**: SSD storage for temporary processing files
- **Network**: Load balancer with SSL termination

### Docker Deployment
```dockerfile
# Example Dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && apt-get install -y \
    tesseract-ocr \
    tesseract-ocr-eng \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### Environment Configuration
```bash
# Production environment variables
DATABASE_URL=postgresql://user:pass@host:5432/esg_db
S3_BUCKET=esg-documents-prod
AWS_REGION=us-west-2
REDIS_URL=redis://cache:6379/0
LOG_LEVEL=INFO
MAX_WORKERS=4
```

### Kubernetes Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: esg-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: esg-backend
  template:
    metadata:
      labels:
        app: esg-backend
    spec:
      containers:
      - name: backend
        image: esg-backend:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
```

### Production Checklist
- [ ] **Database Migration**: Set up PostgreSQL with proper indexing
- [ ] **Authentication**: Implement JWT/OAuth2 authentication
- [ ] **Rate Limiting**: Add API rate limiting and throttling
- [ ] **Background Tasks**: Use Celery/RQ for async processing
- [ ] **File Storage**: Configure cloud storage integration
- [ ] **Logging**: Structured logging with log aggregation
- [ ] **Monitoring**: APM, metrics, and alerting setup
- [ ] **SSL/TLS**: HTTPS configuration with proper certificates
- [ ] **Backup Strategy**: Database and file backup procedures
- [ ] **Security**: Input validation, CSRF protection, security headers

## Troubleshooting

**Tesseract not found:**
- The application will continue to work without Tesseract but OCR will be skipped
- To enable OCR: ensure Tesseract is installed and in PATH
- On Windows, you may need to set `pytesseract.pytesseract.tesseract_cmd`
- Check installation: `tesseract --version`

**Export button not working:**
- The frontend export functionality downloads results as JSON files
- Alternatively, use the API endpoint `/api/export/{doc_id}`

**Processing fails:**
- Check file is a valid PDF under 50MB
- Review console logs for specific error messages
- Ensure uploads directory exists and is writable

**Memory issues:**
- Large PDFs may consume significant memory
- Consider implementing streaming processing for production

**Accuracy issues:**
- OCR accuracy depends on document quality
- Fine-tune fuzzy matching thresholds in `utils/extract.py`

## üìä Performance & Monitoring

### Performance Metrics
- **Processing Speed**: ~2-5 seconds per page for selectable text
- **OCR Processing**: ~10-30 seconds per page depending on quality
- **Memory Usage**: ~100-500MB per document depending on size
- **Throughput**: 50-100 documents/hour with 4 workers
- **Accuracy**: 85-95% framework detection rate



### Logging Configuration
```python
# Example logging setup
import logging
import structlog

logging.basicConfig(
    format="%(message)s",
    stream=sys.stdout,
    level=logging.INFO,
)

structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)
```

### Performance Optimization
- **Text Extraction**: PyMuPDF is ~5x faster than pdfminer for most documents
- **OCR Optimization**: Process only pages with insufficient text (<200 chars)
- **Memory Management**: Stream large files, clean up temporary data
- **Database Indexing**: Index on document_id, status, and created_at fields
- **Caching**: Consider Redis for frequently accessed results

### Scaling Considerations
- **Horizontal Scaling**: Use load balancer with sticky sessions
- **Background Processing**: Move to async task queue (Celery/RQ)
- **File Storage**: Implement cloud storage for multi-instance deployments
- **Database**: Use connection pooling and read replicas for high load
- **CDN**: Cache static assets and export files